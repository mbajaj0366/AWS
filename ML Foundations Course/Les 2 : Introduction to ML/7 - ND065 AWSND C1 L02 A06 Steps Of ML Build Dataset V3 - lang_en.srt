1
00:00:00,000 --> 00:00:03,360
The next step in the machine learning workflow is to build

2
00:00:03,360 --> 00:00:07,915
a dataset that can be used to solve your machine learning-based problem.

3
00:00:07,915 --> 00:00:12,015
Working with data is perhaps the most overlooked,

4
00:00:12,015 --> 00:00:15,945
yet most important step of the machine learning process.

5
00:00:15,945 --> 00:00:19,425
Forbes did a survey back in 2016,

6
00:00:19,425 --> 00:00:21,780
which showed that about 80 percent of

7
00:00:21,780 --> 00:00:26,550
machine learning engineer time is spent preparing data.

8
00:00:26,550 --> 00:00:31,395
Understanding the data we are working with, really understanding it,

9
00:00:31,395 --> 00:00:34,455
helps us select data models and algorithms that

10
00:00:34,455 --> 00:00:39,330
ultimately enable us to have a more effective machine learning solution.

11
00:00:39,330 --> 00:00:42,950
There are four ways to break down the data portion of

12
00:00:42,950 --> 00:00:47,165
the machine learning workflow: data collection,

13
00:00:47,165 --> 00:00:53,810
inspection, summary statistics, and data visualization.

14
00:00:53,810 --> 00:00:56,165
Each plays an important role.

15
00:00:56,165 --> 00:00:59,335
Let's take a deeper look at each step.

16
00:00:59,335 --> 00:01:03,905
The first step is to gather data relevant to your problem.

17
00:01:03,905 --> 00:01:07,070
For example, if you're trying to build a system

18
00:01:07,070 --> 00:01:10,310
to detect if a cat is present in an image or not,

19
00:01:10,310 --> 00:01:12,575
you could take a lot of pictures,

20
00:01:12,575 --> 00:01:16,130
some of which contain cats or some of which don't.

21
00:01:16,130 --> 00:01:19,625
Note that you can find a lot of public datasets,

22
00:01:19,625 --> 00:01:22,160
so you might try some quick Internet searches,

23
00:01:22,160 --> 00:01:25,250
if you're still early in your exploration.

24
00:01:25,250 --> 00:01:29,194
The format, whether it is labeled or unlabeled,

25
00:01:29,194 --> 00:01:31,685
and availability of data will

26
00:01:31,685 --> 00:01:35,410
ultimately determine the machine learning task you can solve.

27
00:01:35,410 --> 00:01:37,655
Now that you have some data,

28
00:01:37,655 --> 00:01:41,330
it's essential to inspect the integrity of the data.

29
00:01:41,330 --> 00:01:45,130
Don't assume any data you find is high-quality.

30
00:01:45,130 --> 00:01:47,695
The quality or lack thereof,

31
00:01:47,695 --> 00:01:53,420
will ultimately have a massive impact on how well you can expect your model to perform.

32
00:01:53,420 --> 00:01:55,505
As you explore your data,

33
00:01:55,505 --> 00:01:59,695
you're trying to identify anything that's outside the norm.

34
00:01:59,695 --> 00:02:04,115
You're also looking for any missing or incomplete data.

35
00:02:04,115 --> 00:02:07,240
This could be very important information.

36
00:02:07,240 --> 00:02:10,760
Many models prefer numeric data.

37
00:02:10,760 --> 00:02:14,210
The question is, does any of the data need to be

38
00:02:14,210 --> 00:02:18,550
transformed to be able to work with the model type you're working on?

39
00:02:18,550 --> 00:02:22,250
A great way to better your data is to use

40
00:02:22,250 --> 00:02:26,290
summary statistics and create data visualization.

41
00:02:26,290 --> 00:02:30,640
For example, take a look at this fictionalized data.

42
00:02:30,640 --> 00:02:35,660
You can very clearly see different clusters of data here.

43
00:02:35,660 --> 00:02:39,800
Summary statistics allow you to see trends in your data,

44
00:02:39,800 --> 00:02:44,165
which can help you better understand what the data is communicating.

45
00:02:44,165 --> 00:02:49,865
There are many statistical tools you can use to calculate things like mean,

46
00:02:49,865 --> 00:02:55,430
interquartile range or short form IQR, and standard deviation.

47
00:02:55,430 --> 00:02:58,865
These tools can give you insight into the scope,

48
00:02:58,865 --> 00:03:01,730
scale, and shape of the dataset.

49
00:03:01,730 --> 00:03:08,250
You might also detect outliers that you might have missed using other methods.

